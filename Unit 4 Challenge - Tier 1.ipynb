{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lm6ENPHFoQuv"
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier 1 Complete\n",
    "\n",
    "\n",
    "## Objectives\n",
    "Hey! Great job getting through those challenging DataCamp courses. You're learning a lot in a short span of time - so let's apply your knowledge in the real world. \n",
    "\n",
    "In this notebook, we're going to apply the skills you've been learning, bridging the gap between the controlled environment of DataCamp and the *slightly* messier work that data scientists do with actual datasets!\n",
    "\n",
    "Here’s the mystery we’re going to solve: ***which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?***\n",
    "\n",
    "\n",
    "A borough is just a fancy word for district. You may be familiar with the five boroughs of New York… [well, there are 32 boroughs within Greater London](https://en.wikipedia.org/wiki/London_boroughs). Some of them are more desirable areas to live in, and the data will reflect that with a greater rise in housing prices.\n",
    "\n",
    "This is the Tier One notebook, which is the easiest tier. More of the code has been filled in already for you, so you have to less research on how to complete the lines. We ask that you only complete this tier if you've given Tiers Two and Three your best effort and been thwarted. We also ask, once you complete this tier, to go back to the highest difficulty level and give it another go. We really want you to internalize the skills you're learning.\n",
    "\n",
    "\n",
    "This challenge will make use of only what you learned in the following DataCamp courses: \n",
    "- Prework courses (Introduction to Python for Data Science, Intermediate Python for Data Science)\n",
    "- Data Types for Data Science\n",
    "- Python Data Science Toolbox (Part One) \n",
    "- pandas Foundations\n",
    "- Manipulating DataFrames with pandas\n",
    "- Merging DataFrames with pandas\n",
    "\n",
    "Of the tools, techniques and concepts in the above DataCamp courses, this challenge should require the application of the following: \n",
    "- **pandas**\n",
    "    - **data ingestion and inspection** (pandas Foundations, Module One) \n",
    "    - **exploratory data analysis** (pandas Foundations, Module Two)\n",
    "    - **tidying and cleaning** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **transforming DataFrames** (Manipulating DataFrames with pandas, Module One)\n",
    "    - **subsetting DataFrames with lists** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **filtering DataFrames** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **grouping data** (Manipulating DataFrames with pandas, Module Four) \n",
    "    - **melting data** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **advanced indexing** (Manipulating DataFrames with pandas, Module Four) \n",
    "- **matplotlib** (Intermediate Python for Data Science, Module One)\n",
    "- **fundamental data types** (Data Types for Data Science, Module One) \n",
    "- **dictionaries** (Intermediate Python for Data Science, Module Two)\n",
    "- **handling dates and times** (Data Types for Data Science, Module Four)\n",
    "- **function definition** (Python Data Science Toolbox - Part One, Module One)\n",
    "- **default arguments, variable length, and scope** (Python Data Science Toolbox - Part One, Module Two) \n",
    "- **lambda functions and error handling** (Python Data Science Toolbox - Part One, Module Four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6PO84SgoQux"
   },
   "source": [
    "## The Data Science Pipeline\n",
    "Data Science is magical. In this case study, you'll get to apply some complex machine learning algorithms. But as  [David Spiegelhalter](https://www.youtube.com/watch?v=oUs1uvsz0Ok) reminds us, there is no substitute for simply **taking a really, really good look at the data.** Sometimes, this is all we need to answer our question.\n",
    "\n",
    "Data Science projects generally adhere to the four stages of Data Science Pipeline:\n",
    "1. Sourcing and loading \n",
    "2. Cleaning, transforming, and visualizing \n",
    "3. Modeling \n",
    "4. Evaluating and concluding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78-L90uhoQuy"
   },
   "source": [
    "### 1. Sourcing and Loading \n",
    "\n",
    "Any Data Science project kicks off by importing  ***pandas***. The documentation of this wonderful library can be found [here](https://pandas.pydata.org/). As you've seen, pandas is conveniently connected to the [Numpy](http://www.numpy.org/) and [Matplotlib](https://matplotlib.org/) libraries. \n",
    "\n",
    "***Hint:*** This part of the data science pipeline will test those skills you acquired in the pandas Foundations course, Module One. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BC3bSm2BoQuz"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiAdD4KIoQuz"
   },
   "outputs": [],
   "source": [
    "# Let's import the pandas, numpy libraries as pd, and np respectively. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the pyplot collection of functions from matplotlib, as plt \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ws2MT3WDoQu2"
   },
   "source": [
    "#### 1.2.  Loading the data\n",
    "\n",
    "\n",
    "Your the data comes from the [London Datastore](https://data.london.gov.uk/): a free, open-source data-sharing portal with a massive range of London-oriented datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hT3nSEiEoQu3"
   },
   "outputs": [],
   "source": [
    "# First, make a variable called url_LondonHousePrices, and assign it the following link, enclosed in quotation-marks as a string:\n",
    "# https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\n",
    "\n",
    "url_LondonHousePrices = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n",
    "properties = pd.read_excel(url_LondonHousePrices, sheet_name='Average price', index_col= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eRL0WFhQoQu5"
   },
   "source": [
    "### 2. Cleaning, transforming, and visualizing \n",
    "This second stage is arguably the most important part of any Data Science project. The first thing to do is take a proper look at the data. Cleaning forms the majority of this stage, and can be done both before or after Transformation.\n",
    "\n",
    "The end goal of data cleaning is to have tidy data. When data is tidy: \n",
    "\n",
    "1. Each variable has a column.\n",
    "2. Each observation forms a row.\n",
    "\n",
    "Keep the end goal in mind as you move through this process, every step will take you closer. \n",
    "\n",
    "\n",
    "\n",
    "***Hint:*** This part of the data science pipeline should test those skills you acquired in: \n",
    "- Intermediate Python for data science, all modules.\n",
    "- pandas Foundations, all modules. \n",
    "- Manipulating DataFrames with pandas, all modules.\n",
    "- Data Types for Data Science, Module Four.\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tfGJTJeboQu5"
   },
   "source": [
    "#### 2.1. Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_QAqw8OoQu6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 48)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First off, let's use .shape feature of pandas DataFrames to look at the number of rows and columns. \n",
    "properties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5x3iljSoQu8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>Enfield</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-01</th>\n",
       "      <td>91449</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>81671.5</td>\n",
       "      <td>120933</td>\n",
       "      <td>69158.2</td>\n",
       "      <td>79885.9</td>\n",
       "      <td>72514.7</td>\n",
       "      <td>...</td>\n",
       "      <td>43958.5</td>\n",
       "      <td>44803.4</td>\n",
       "      <td>45544.5</td>\n",
       "      <td>48527.5</td>\n",
       "      <td>56701.6</td>\n",
       "      <td>74435.8</td>\n",
       "      <td>64018.9</td>\n",
       "      <td>54705.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-02-01</th>\n",
       "      <td>82202.8</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>81657.6</td>\n",
       "      <td>119509</td>\n",
       "      <td>68951.1</td>\n",
       "      <td>80897.1</td>\n",
       "      <td>73155.2</td>\n",
       "      <td>...</td>\n",
       "      <td>43925.4</td>\n",
       "      <td>44528.8</td>\n",
       "      <td>46051.6</td>\n",
       "      <td>49341.3</td>\n",
       "      <td>56593.6</td>\n",
       "      <td>72777.9</td>\n",
       "      <td>63715</td>\n",
       "      <td>54356.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-03-01</th>\n",
       "      <td>79120.7</td>\n",
       "      <td>51269</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>81449.3</td>\n",
       "      <td>120282</td>\n",
       "      <td>68712.4</td>\n",
       "      <td>81379.9</td>\n",
       "      <td>72190.4</td>\n",
       "      <td>...</td>\n",
       "      <td>44434.9</td>\n",
       "      <td>45200.5</td>\n",
       "      <td>45383.8</td>\n",
       "      <td>49442.2</td>\n",
       "      <td>56171.2</td>\n",
       "      <td>73896.8</td>\n",
       "      <td>64113.6</td>\n",
       "      <td>53583.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-04-01</th>\n",
       "      <td>77101.2</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>81124.4</td>\n",
       "      <td>120098</td>\n",
       "      <td>68610</td>\n",
       "      <td>82188.9</td>\n",
       "      <td>71442.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44267.8</td>\n",
       "      <td>45614.3</td>\n",
       "      <td>46124.2</td>\n",
       "      <td>49455.9</td>\n",
       "      <td>56567.9</td>\n",
       "      <td>74455.3</td>\n",
       "      <td>64623.2</td>\n",
       "      <td>54786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           City of London Barking & Dagenham     Barnet     Bexley      Brent  \\\n",
       "NaT             E09000001          E09000002  E09000003  E09000004  E09000005   \n",
       "1995-01-01          91449            50460.2    93284.5    64958.1    71306.6   \n",
       "1995-02-01        82202.8            51085.8    93190.2    64787.9    72022.3   \n",
       "1995-03-01        79120.7              51269    92247.5    64367.5    72015.8   \n",
       "1995-04-01        77101.2            53133.5    90762.9    64277.7    72965.6   \n",
       "\n",
       "              Bromley     Camden    Croydon     Ealing    Enfield    ...      \\\n",
       "NaT         E09000006  E09000007  E09000008  E09000009  E09000010    ...       \n",
       "1995-01-01    81671.5     120933    69158.2    79885.9    72514.7    ...       \n",
       "1995-02-01    81657.6     119509    68951.1    80897.1    73155.2    ...       \n",
       "1995-03-01    81449.3     120282    68712.4    81379.9    72190.4    ...       \n",
       "1995-04-01    81124.4     120098      68610    82188.9    71442.9    ...       \n",
       "\n",
       "           NORTH WEST YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS  \\\n",
       "NaT         E12000002          E12000003     E12000004     E12000005   \n",
       "1995-01-01    43958.5            44803.4       45544.5       48527.5   \n",
       "1995-02-01    43925.4            44528.8       46051.6       49341.3   \n",
       "1995-03-01    44434.9            45200.5       45383.8       49442.2   \n",
       "1995-04-01    44267.8            45614.3       46124.2       49455.9   \n",
       "\n",
       "           EAST OF ENGLAND     LONDON SOUTH EAST SOUTH WEST Unnamed: 46  \\\n",
       "NaT              E12000006  E12000007  E12000008  E12000009         NaN   \n",
       "1995-01-01         56701.6    74435.8    64018.9    54705.2         NaN   \n",
       "1995-02-01         56593.6    72777.9      63715    54356.1         NaN   \n",
       "1995-03-01         56171.2    73896.8    64113.6    53583.1         NaN   \n",
       "1995-04-01         56567.9    74455.3    64623.2      54786         NaN   \n",
       "\n",
       "              England  \n",
       "NaT         E92000001  \n",
       "1995-01-01    53202.8  \n",
       "1995-02-01    53096.2  \n",
       "1995-03-01    53201.3  \n",
       "1995-04-01    53590.9  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the .head() method, let's check out the state of our dataset.  \n",
    "properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cCBLbVS_oQu-"
   },
   "source": [
    "Oh no! What are you supposed to do with this?\n",
    "\n",
    "You've got the data, but it doesn't look tidy. At this stage, you'd struggle to perform analysis on it. It is normal for your initial data set to be formatted in a way that is not conducive to analysis. A big part of your job is fixing that. \n",
    "\n",
    "Best practice is for pandas DataFrames to contain the **observations of interest** as rows, and the features of those observations as columns. You want **tidy** DataFrames: whose rows are observations and whose columns are variables.\n",
    "\n",
    "\n",
    "Notice here that the column headings are the *particular* boroughs, which is your observation of interest. The first column contains datetime objects that capture a particular month and year, which is a variable. Most of the other cell-values are the average proprety values of the borough corresponding to that time stamp. \n",
    "\n",
    "Clearly, you need to roll up your sleeves and do some  **cleaning**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2P95BHw5oQu_"
   },
   "source": [
    "####  2.2. Cleaning the data (Part 1)\n",
    "Data cleaning has a bad rep, but remember what your momma told you: cleanliness is next to godliness. Data cleaning can be really satisfying and fun. In the dark ages of programming, data cleaning was a tedious and difficult ordeal. Nowadays, new and improved tools have simplified the process. Getting good at data cleaning opens up a world of possibilities for data scientists and programmers. \n",
    " \n",
    "The first operation you want to do on the dataset is called **transposition**. You *transpose* a table when you flip the columns into rows, and *vice versa*. \n",
    "\n",
    "If you transpose this DataFrame then the borough names will become the row indices, and the date time objects will become the column headers. Since your end goal is tidy data, where each row will represent a borough and each column will contain data about that borough at a certain point in time, transposing the table bring us closer to where you want to be.\n",
    "\n",
    "Python makes transposition simple.\n",
    "\n",
    "Each pandas DataFrame already has the *.T* attribute which is the transposed version of that DataFrame.\n",
    "\n",
    "Assign the transposed version of the original to a new variable. Let’s call it *properties_T*. \n",
    "\n",
    "Boom! You’ve got a transposed table to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "28P8-GkeoQu_"
   },
   "outputs": [],
   "source": [
    "# Do this here\n",
    "properties_T = properties.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BcjtHOwoQvB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaT</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>1995-09-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-05-01 00:00:00</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <th>2019-08-01 00:00:00</th>\n",
       "      <th>2019-09-01 00:00:00</th>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <th>2020-02-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>104473</td>\n",
       "      <td>...</td>\n",
       "      <td>718930</td>\n",
       "      <td>761786</td>\n",
       "      <td>738370</td>\n",
       "      <td>795632</td>\n",
       "      <td>792195</td>\n",
       "      <td>827375</td>\n",
       "      <td>778870</td>\n",
       "      <td>739645</td>\n",
       "      <td>748457</td>\n",
       "      <td>730282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>51471.6</td>\n",
       "      <td>...</td>\n",
       "      <td>295829</td>\n",
       "      <td>295179</td>\n",
       "      <td>299060</td>\n",
       "      <td>300402</td>\n",
       "      <td>305488</td>\n",
       "      <td>304563</td>\n",
       "      <td>306376</td>\n",
       "      <td>301435</td>\n",
       "      <td>303631</td>\n",
       "      <td>298960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>93273.1</td>\n",
       "      <td>...</td>\n",
       "      <td>504765</td>\n",
       "      <td>512818</td>\n",
       "      <td>515235</td>\n",
       "      <td>528958</td>\n",
       "      <td>527691</td>\n",
       "      <td>525985</td>\n",
       "      <td>522683</td>\n",
       "      <td>519037</td>\n",
       "      <td>518271</td>\n",
       "      <td>526024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>64509.5</td>\n",
       "      <td>...</td>\n",
       "      <td>337543</td>\n",
       "      <td>339684</td>\n",
       "      <td>338257</td>\n",
       "      <td>337745</td>\n",
       "      <td>334075</td>\n",
       "      <td>333853</td>\n",
       "      <td>334044</td>\n",
       "      <td>336579</td>\n",
       "      <td>335492</td>\n",
       "      <td>341588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>73789.5</td>\n",
       "      <td>...</td>\n",
       "      <td>482101</td>\n",
       "      <td>474460</td>\n",
       "      <td>472981</td>\n",
       "      <td>487091</td>\n",
       "      <td>500800</td>\n",
       "      <td>494697</td>\n",
       "      <td>432511</td>\n",
       "      <td>429917</td>\n",
       "      <td>425607</td>\n",
       "      <td>479542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          NaT 1995-01-01 1995-02-01 1995-03-01 1995-04-01  \\\n",
       "City of London      E09000001      91449    82202.8    79120.7    77101.2   \n",
       "Barking & Dagenham  E09000002    50460.2    51085.8      51269    53133.5   \n",
       "Barnet              E09000003    93284.5    93190.2    92247.5    90762.9   \n",
       "Bexley              E09000004    64958.1    64787.9    64367.5    64277.7   \n",
       "Brent               E09000005    71306.6    72022.3    72015.8    72965.6   \n",
       "\n",
       "                   1995-05-01 1995-06-01 1995-07-01 1995-08-01 1995-09-01  \\\n",
       "City of London        84409.1    94900.5     110128     112329     104473   \n",
       "Barking & Dagenham    53042.2    53700.3    52113.1    52232.2    51471.6   \n",
       "Barnet                  90258    90107.2    91441.2    92361.3    93273.1   \n",
       "Bexley                63997.1    64252.3    63722.7    64432.6    64509.5   \n",
       "Brent                   73704    74310.5      74127      73547    73789.5   \n",
       "\n",
       "                      ...     2019-05-01 2019-06-01 2019-07-01 2019-08-01  \\\n",
       "City of London        ...         718930     761786     738370     795632   \n",
       "Barking & Dagenham    ...         295829     295179     299060     300402   \n",
       "Barnet                ...         504765     512818     515235     528958   \n",
       "Bexley                ...         337543     339684     338257     337745   \n",
       "Brent                 ...         482101     474460     472981     487091   \n",
       "\n",
       "                   2019-09-01 2019-10-01 2019-11-01 2019-12-01 2020-01-01  \\\n",
       "City of London         792195     827375     778870     739645     748457   \n",
       "Barking & Dagenham     305488     304563     306376     301435     303631   \n",
       "Barnet                 527691     525985     522683     519037     518271   \n",
       "Bexley                 334075     333853     334044     336579     335492   \n",
       "Brent                  500800     494697     432511     429917     425607   \n",
       "\n",
       "                   2020-02-01  \n",
       "City of London         730282  \n",
       "Barking & Dagenham     298960  \n",
       "Barnet                 526024  \n",
       "Bexley                 341588  \n",
       "Brent                  479542  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the head of our new Transposed DataFrame. \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eBY9f1GeoQvD"
   },
   "source": [
    "You've made some progress! But with new progress comes new issues. For one, the row indices of our DataFrame contain the names of the boroughs. You should never have a piece of information we want to analyze as an index, this information should be within the DataFrame itself. The indices should just be a unique ID, almost always a number.\n",
    "\n",
    "Those names are perhaps the most important piece of information! Put them where you can work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g1XrFC88oQvE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['City of London', 'Barking & Dagenham', 'Barnet', 'Bexley', 'Brent',\n",
       "       'Bromley', 'Camden', 'Croydon', 'Ealing', 'Enfield', 'Greenwich',\n",
       "       'Hackney', 'Hammersmith & Fulham', 'Haringey', 'Harrow', 'Havering',\n",
       "       'Hillingdon', 'Hounslow', 'Islington', 'Kensington & Chelsea',\n",
       "       'Kingston upon Thames', 'Lambeth', 'Lewisham', 'Merton', 'Newham',\n",
       "       'Redbridge', 'Richmond upon Thames', 'Southwark', 'Sutton',\n",
       "       'Tower Hamlets', 'Waltham Forest', 'Wandsworth', 'Westminster',\n",
       "       'Unnamed: 33', 'Inner London', 'Outer London', 'Unnamed: 36',\n",
       "       'NORTH EAST', 'NORTH WEST', 'YORKS & THE HUMBER', 'EAST MIDLANDS',\n",
       "       'WEST MIDLANDS', 'EAST OF ENGLAND', 'LONDON', 'SOUTH EAST',\n",
       "       'SOUTH WEST', 'Unnamed: 46', 'England'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To confirm what our row indices are, let's call the .index variable on our properties_T DataFrame. \n",
    "properties_T.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-JE-5F_oQvG"
   },
   "outputs": [],
   "source": [
    "# Our suspicion was correct. \n",
    "# Call the .reset_index() method on properties_T to reset the indices, and the reassign the result to properties_T: \n",
    "properties_T = properties_T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rEXEl1loQvH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=48, step=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's check out our DataFrames indices: \n",
    "properties_T.index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_Fu5UAcoQvK"
   },
   "source": [
    "Progress! \n",
    "\n",
    "The indicies are now a numerical RangeIndex, exactly what you want. \n",
    "\n",
    "**Note**: if you call the reset_index() line more than once, you'll get an error because a whole extra level of row indices will have been inserted! If you do this, don't worry. Just hit Kernel > Restart, then run all the cells up to here to get back to where you were. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_MDLMFp0oQvK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>NaT</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-05-01 00:00:00</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <th>2019-08-01 00:00:00</th>\n",
       "      <th>2019-09-01 00:00:00</th>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <th>2020-02-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>718930</td>\n",
       "      <td>761786</td>\n",
       "      <td>738370</td>\n",
       "      <td>795632</td>\n",
       "      <td>792195</td>\n",
       "      <td>827375</td>\n",
       "      <td>778870</td>\n",
       "      <td>739645</td>\n",
       "      <td>748457</td>\n",
       "      <td>730282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>295829</td>\n",
       "      <td>295179</td>\n",
       "      <td>299060</td>\n",
       "      <td>300402</td>\n",
       "      <td>305488</td>\n",
       "      <td>304563</td>\n",
       "      <td>306376</td>\n",
       "      <td>301435</td>\n",
       "      <td>303631</td>\n",
       "      <td>298960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>504765</td>\n",
       "      <td>512818</td>\n",
       "      <td>515235</td>\n",
       "      <td>528958</td>\n",
       "      <td>527691</td>\n",
       "      <td>525985</td>\n",
       "      <td>522683</td>\n",
       "      <td>519037</td>\n",
       "      <td>518271</td>\n",
       "      <td>526024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>337543</td>\n",
       "      <td>339684</td>\n",
       "      <td>338257</td>\n",
       "      <td>337745</td>\n",
       "      <td>334075</td>\n",
       "      <td>333853</td>\n",
       "      <td>334044</td>\n",
       "      <td>336579</td>\n",
       "      <td>335492</td>\n",
       "      <td>341588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>...</td>\n",
       "      <td>482101</td>\n",
       "      <td>474460</td>\n",
       "      <td>472981</td>\n",
       "      <td>487091</td>\n",
       "      <td>500800</td>\n",
       "      <td>494697</td>\n",
       "      <td>432511</td>\n",
       "      <td>429917</td>\n",
       "      <td>425607</td>\n",
       "      <td>479542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                index        NaN 1995-01-01 00:00:00 1995-02-01 00:00:00  \\\n",
       "0      City of London  E09000001               91449             82202.8   \n",
       "1  Barking & Dagenham  E09000002             50460.2             51085.8   \n",
       "2              Barnet  E09000003             93284.5             93190.2   \n",
       "3              Bexley  E09000004             64958.1             64787.9   \n",
       "4               Brent  E09000005             71306.6             72022.3   \n",
       "\n",
       "  1995-03-01 00:00:00 1995-04-01 00:00:00 1995-05-01 00:00:00  \\\n",
       "0             79120.7             77101.2             84409.1   \n",
       "1               51269             53133.5             53042.2   \n",
       "2             92247.5             90762.9               90258   \n",
       "3             64367.5             64277.7             63997.1   \n",
       "4             72015.8             72965.6               73704   \n",
       "\n",
       "  1995-06-01 00:00:00 1995-07-01 00:00:00 1995-08-01 00:00:00  \\\n",
       "0             94900.5              110128              112329   \n",
       "1             53700.3             52113.1             52232.2   \n",
       "2             90107.2             91441.2             92361.3   \n",
       "3             64252.3             63722.7             64432.6   \n",
       "4             74310.5               74127               73547   \n",
       "\n",
       "          ...         2019-05-01 00:00:00 2019-06-01 00:00:00  \\\n",
       "0         ...                      718930              761786   \n",
       "1         ...                      295829              295179   \n",
       "2         ...                      504765              512818   \n",
       "3         ...                      337543              339684   \n",
       "4         ...                      482101              474460   \n",
       "\n",
       "  2019-07-01 00:00:00 2019-08-01 00:00:00 2019-09-01 00:00:00  \\\n",
       "0              738370              795632              792195   \n",
       "1              299060              300402              305488   \n",
       "2              515235              528958              527691   \n",
       "3              338257              337745              334075   \n",
       "4              472981              487091              500800   \n",
       "\n",
       "  2019-10-01 00:00:00 2019-11-01 00:00:00 2019-12-01 00:00:00  \\\n",
       "0              827375              778870              739645   \n",
       "1              304563              306376              301435   \n",
       "2              525985              522683              519037   \n",
       "3              333853              334044              336579   \n",
       "4              494697              432511              429917   \n",
       "\n",
       "  2020-01-01 00:00:00 2020-02-01 00:00:00  \n",
       "0              748457              730282  \n",
       "1              303631              298960  \n",
       "2              518271              526024  \n",
       "3              335492              341588  \n",
       "4              425607              479542  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the head() function again on properties_T to check out the new row indices: \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "luuvOpemoQvN"
   },
   "source": [
    "You're getting somewhere, but your column headings are mainly just integers. The first one is the string 'index' and the rest are integers ranging from 0 to 296, inclusive.\n",
    "\n",
    "For the ultimate aim of having a *tidy* DataFrame, you'll turn the datetimes found along the first row (at index 0) into the column headings.  The resulting DataFrame will have boroughs as rows, the columns as dates (each representing a particular month), and the cell-values as the average property value sold in that borough for that month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bwmuRMm-oQvN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([            'index',                 NaT, 1995-01-01 00:00:00,\n",
       "       1995-02-01 00:00:00, 1995-03-01 00:00:00, 1995-04-01 00:00:00,\n",
       "       1995-05-01 00:00:00, 1995-06-01 00:00:00, 1995-07-01 00:00:00,\n",
       "       1995-08-01 00:00:00,\n",
       "       ...\n",
       "       2019-05-01 00:00:00, 2019-06-01 00:00:00, 2019-07-01 00:00:00,\n",
       "       2019-08-01 00:00:00, 2019-09-01 00:00:00, 2019-10-01 00:00:00,\n",
       "       2019-11-01 00:00:00, 2019-12-01 00:00:00, 2020-01-01 00:00:00,\n",
       "       2020-02-01 00:00:00],\n",
       "      dtype='object', length=304)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To confirm that our DataFrame's columns are mainly just integers, call the .columns feature on our DataFrame:\n",
    "properties_T.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Z0m7gyWoQvP"
   },
   "source": [
    "To confirm that the first row contains the proper values for column headings, use the  ***iloc[] method*** on our *properties_T* DataFrame. Use index 0. You'll recall from DataCamp that if you use single square brackets, you'll return a series. If you use double square brackets, a DataFrame is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fP9pJ6EnoQvQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>NaT</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-05-01 00:00:00</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <th>2019-08-01 00:00:00</th>\n",
       "      <th>2019-09-01 00:00:00</th>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <th>2020-02-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>718930</td>\n",
       "      <td>761786</td>\n",
       "      <td>738370</td>\n",
       "      <td>795632</td>\n",
       "      <td>792195</td>\n",
       "      <td>827375</td>\n",
       "      <td>778870</td>\n",
       "      <td>739645</td>\n",
       "      <td>748457</td>\n",
       "      <td>730282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index        NaN 1995-01-01 00:00:00 1995-02-01 00:00:00  \\\n",
       "0  City of London  E09000001               91449             82202.8   \n",
       "\n",
       "  1995-03-01 00:00:00 1995-04-01 00:00:00 1995-05-01 00:00:00  \\\n",
       "0             79120.7             77101.2             84409.1   \n",
       "\n",
       "  1995-06-01 00:00:00 1995-07-01 00:00:00 1995-08-01 00:00:00  \\\n",
       "0             94900.5              110128              112329   \n",
       "\n",
       "          ...         2019-05-01 00:00:00 2019-06-01 00:00:00  \\\n",
       "0         ...                      718930              761786   \n",
       "\n",
       "  2019-07-01 00:00:00 2019-08-01 00:00:00 2019-09-01 00:00:00  \\\n",
       "0              738370              795632              792195   \n",
       "\n",
       "  2019-10-01 00:00:00 2019-11-01 00:00:00 2019-12-01 00:00:00  \\\n",
       "0              827375              778870              739645   \n",
       "\n",
       "  2020-01-01 00:00:00 2020-02-01 00:00:00  \n",
       "0              748457              730282  \n",
       "\n",
       "[1 rows x 304 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the iloc[] method with double square brackets on the properties_T DataFrame, to see the row at index 0. \n",
    "properties_T.iloc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JXHvYb0JoQvR"
   },
   "source": [
    "**Notice that these values are all the months from January 1995 to August 2019, inclusive**. You can reassign the columns of your DataFrame the values within this row at index 0 by making use of the *.columns* feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPZKKSyYoQvS"
   },
   "outputs": [],
   "source": [
    "# Try this now. \n",
    "properties_T.columns = properties_T.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7C8FoHoQvU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City of London</th>\n",
       "      <th>E09000001</th>\n",
       "      <th>91448.98487</th>\n",
       "      <th>82202.77314</th>\n",
       "      <th>79120.70256</th>\n",
       "      <th>77101.20804</th>\n",
       "      <th>84409.14932</th>\n",
       "      <th>94900.51244</th>\n",
       "      <th>110128.0423</th>\n",
       "      <th>112329.4376</th>\n",
       "      <th>...</th>\n",
       "      <th>718929.8777</th>\n",
       "      <th>761786.2425</th>\n",
       "      <th>738370.3891</th>\n",
       "      <th>795632.4582</th>\n",
       "      <th>792195.0059</th>\n",
       "      <th>827374.8332</th>\n",
       "      <th>778869.8314</th>\n",
       "      <th>739644.7006</th>\n",
       "      <th>748456.8177</th>\n",
       "      <th>730282.1054</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>718930</td>\n",
       "      <td>761786</td>\n",
       "      <td>738370</td>\n",
       "      <td>795632</td>\n",
       "      <td>792195</td>\n",
       "      <td>827375</td>\n",
       "      <td>778870</td>\n",
       "      <td>739645</td>\n",
       "      <td>748457</td>\n",
       "      <td>730282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>295829</td>\n",
       "      <td>295179</td>\n",
       "      <td>299060</td>\n",
       "      <td>300402</td>\n",
       "      <td>305488</td>\n",
       "      <td>304563</td>\n",
       "      <td>306376</td>\n",
       "      <td>301435</td>\n",
       "      <td>303631</td>\n",
       "      <td>298960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>504765</td>\n",
       "      <td>512818</td>\n",
       "      <td>515235</td>\n",
       "      <td>528958</td>\n",
       "      <td>527691</td>\n",
       "      <td>525985</td>\n",
       "      <td>522683</td>\n",
       "      <td>519037</td>\n",
       "      <td>518271</td>\n",
       "      <td>526024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>337543</td>\n",
       "      <td>339684</td>\n",
       "      <td>338257</td>\n",
       "      <td>337745</td>\n",
       "      <td>334075</td>\n",
       "      <td>333853</td>\n",
       "      <td>334044</td>\n",
       "      <td>336579</td>\n",
       "      <td>335492</td>\n",
       "      <td>341588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>...</td>\n",
       "      <td>482101</td>\n",
       "      <td>474460</td>\n",
       "      <td>472981</td>\n",
       "      <td>487091</td>\n",
       "      <td>500800</td>\n",
       "      <td>494697</td>\n",
       "      <td>432511</td>\n",
       "      <td>429917</td>\n",
       "      <td>425607</td>\n",
       "      <td>479542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0      City of London  E09000001 91448.98487 82202.77314 79120.70256  \\\n",
       "0      City of London  E09000001       91449     82202.8     79120.7   \n",
       "1  Barking & Dagenham  E09000002     50460.2     51085.8       51269   \n",
       "2              Barnet  E09000003     93284.5     93190.2     92247.5   \n",
       "3              Bexley  E09000004     64958.1     64787.9     64367.5   \n",
       "4               Brent  E09000005     71306.6     72022.3     72015.8   \n",
       "\n",
       "0 77101.20804 84409.14932 94900.51244 110128.0423 112329.4376     ...      \\\n",
       "0     77101.2     84409.1     94900.5      110128      112329     ...       \n",
       "1     53133.5     53042.2     53700.3     52113.1     52232.2     ...       \n",
       "2     90762.9       90258     90107.2     91441.2     92361.3     ...       \n",
       "3     64277.7     63997.1     64252.3     63722.7     64432.6     ...       \n",
       "4     72965.6       73704     74310.5       74127       73547     ...       \n",
       "\n",
       "0 718929.8777 761786.2425 738370.3891 795632.4582 792195.0059 827374.8332  \\\n",
       "0      718930      761786      738370      795632      792195      827375   \n",
       "1      295829      295179      299060      300402      305488      304563   \n",
       "2      504765      512818      515235      528958      527691      525985   \n",
       "3      337543      339684      338257      337745      334075      333853   \n",
       "4      482101      474460      472981      487091      500800      494697   \n",
       "\n",
       "0 778869.8314 739644.7006 748456.8177 730282.1054  \n",
       "0      778870      739645      748457      730282  \n",
       "1      306376      301435      303631      298960  \n",
       "2      522683      519037      518271      526024  \n",
       "3      334044      336579      335492      341588  \n",
       "4      432511      429917      425607      479542  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out our DataFrame again: \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQuFG21OoQvW"
   },
   "source": [
    "You need to drop the row at index 0! \n",
    "\n",
    "A good way to do this is reassign *properties_T* with the return value of calling the DataFrame ***drop()*** method, passing 0 as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXGdKJDNoQvW"
   },
   "outputs": [],
   "source": [
    "# Have a go at this now. \n",
    "properties_T = properties_T.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2K9I-lPoQvY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City of London</th>\n",
       "      <th>E09000001</th>\n",
       "      <th>91448.98487</th>\n",
       "      <th>82202.77314</th>\n",
       "      <th>79120.70256</th>\n",
       "      <th>77101.20804</th>\n",
       "      <th>84409.14932</th>\n",
       "      <th>94900.51244</th>\n",
       "      <th>110128.0423</th>\n",
       "      <th>112329.4376</th>\n",
       "      <th>...</th>\n",
       "      <th>718929.8777</th>\n",
       "      <th>761786.2425</th>\n",
       "      <th>738370.3891</th>\n",
       "      <th>795632.4582</th>\n",
       "      <th>792195.0059</th>\n",
       "      <th>827374.8332</th>\n",
       "      <th>778869.8314</th>\n",
       "      <th>739644.7006</th>\n",
       "      <th>748456.8177</th>\n",
       "      <th>730282.1054</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>295829</td>\n",
       "      <td>295179</td>\n",
       "      <td>299060</td>\n",
       "      <td>300402</td>\n",
       "      <td>305488</td>\n",
       "      <td>304563</td>\n",
       "      <td>306376</td>\n",
       "      <td>301435</td>\n",
       "      <td>303631</td>\n",
       "      <td>298960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>504765</td>\n",
       "      <td>512818</td>\n",
       "      <td>515235</td>\n",
       "      <td>528958</td>\n",
       "      <td>527691</td>\n",
       "      <td>525985</td>\n",
       "      <td>522683</td>\n",
       "      <td>519037</td>\n",
       "      <td>518271</td>\n",
       "      <td>526024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>337543</td>\n",
       "      <td>339684</td>\n",
       "      <td>338257</td>\n",
       "      <td>337745</td>\n",
       "      <td>334075</td>\n",
       "      <td>333853</td>\n",
       "      <td>334044</td>\n",
       "      <td>336579</td>\n",
       "      <td>335492</td>\n",
       "      <td>341588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>...</td>\n",
       "      <td>482101</td>\n",
       "      <td>474460</td>\n",
       "      <td>472981</td>\n",
       "      <td>487091</td>\n",
       "      <td>500800</td>\n",
       "      <td>494697</td>\n",
       "      <td>432511</td>\n",
       "      <td>429917</td>\n",
       "      <td>425607</td>\n",
       "      <td>479542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bromley</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>81671.5</td>\n",
       "      <td>81657.6</td>\n",
       "      <td>81449.3</td>\n",
       "      <td>81124.4</td>\n",
       "      <td>81542.6</td>\n",
       "      <td>82382.8</td>\n",
       "      <td>82898.5</td>\n",
       "      <td>82054.4</td>\n",
       "      <td>...</td>\n",
       "      <td>429107</td>\n",
       "      <td>431117</td>\n",
       "      <td>434577</td>\n",
       "      <td>441618</td>\n",
       "      <td>440627</td>\n",
       "      <td>439745</td>\n",
       "      <td>437389</td>\n",
       "      <td>440183</td>\n",
       "      <td>436152</td>\n",
       "      <td>437030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0      City of London  E09000001 91448.98487 82202.77314 79120.70256  \\\n",
       "1  Barking & Dagenham  E09000002     50460.2     51085.8       51269   \n",
       "2              Barnet  E09000003     93284.5     93190.2     92247.5   \n",
       "3              Bexley  E09000004     64958.1     64787.9     64367.5   \n",
       "4               Brent  E09000005     71306.6     72022.3     72015.8   \n",
       "5             Bromley  E09000006     81671.5     81657.6     81449.3   \n",
       "\n",
       "0 77101.20804 84409.14932 94900.51244 110128.0423 112329.4376     ...      \\\n",
       "1     53133.5     53042.2     53700.3     52113.1     52232.2     ...       \n",
       "2     90762.9       90258     90107.2     91441.2     92361.3     ...       \n",
       "3     64277.7     63997.1     64252.3     63722.7     64432.6     ...       \n",
       "4     72965.6       73704     74310.5       74127       73547     ...       \n",
       "5     81124.4     81542.6     82382.8     82898.5     82054.4     ...       \n",
       "\n",
       "0 718929.8777 761786.2425 738370.3891 795632.4582 792195.0059 827374.8332  \\\n",
       "1      295829      295179      299060      300402      305488      304563   \n",
       "2      504765      512818      515235      528958      527691      525985   \n",
       "3      337543      339684      338257      337745      334075      333853   \n",
       "4      482101      474460      472981      487091      500800      494697   \n",
       "5      429107      431117      434577      441618      440627      439745   \n",
       "\n",
       "0 778869.8314 739644.7006 748456.8177 730282.1054  \n",
       "1      306376      301435      303631      298960  \n",
       "2      522683      519037      518271      526024  \n",
       "3      334044      336579      335492      341588  \n",
       "4      432511      429917      425607      479542  \n",
       "5      437389      440183      436152      437030  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now check out our DataFrame again to see how it looks. \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the label [Unnamed: 0] is not in the [index]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1789\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m                     \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1784\u001b[0m                                .format(key=key,\n\u001b[1;32m-> 1785\u001b[1;33m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [Unnamed: 0] is not in the [index]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b3f5a9caf0d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mproperties_T\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1478\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1480\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1796\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1797\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1798\u001b[1;33m                 \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1800\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36merror\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1783\u001b[0m                 raise KeyError(u\"the label [{key}] is not in the [{axis}]\"\n\u001b[0;32m   1784\u001b[0m                                .format(key=key,\n\u001b[1;32m-> 1785\u001b[1;33m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'the label [Unnamed: 0] is not in the [index]'"
     ]
    }
   ],
   "source": [
    "properties_T.['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "njB288AGoQvc"
   },
   "source": [
    "You're slowly but surely getting there! Exciting, right? \n",
    "\n",
    "**Each column now represents a month and year, and each cell-value represents the average price of houses sold in borough of the corresponding row**. \n",
    "\n",
    "You have total control over your data! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bp-6ak7DoQvd"
   },
   "source": [
    "#### 2.3. Cleaning the data (Part 2)\n",
    "You can see from the *.head()* list call that you need to rename some columns. \n",
    "\n",
    "'Unnamed: 0' should be something like 'London Borough' and 'NaN' should  be changed. \n",
    "\n",
    "Recall, that pandas DataFrames have a ***.rename()*** method. One of the keyworded arguments to this method is *columns*. You can assign it a dictionary whose keys are the current column names you want to change, and whose values are the desired new names.\n",
    "\n",
    "**Note**: you can change the 'Unnamed: 0' name of the first column just by including that string as a key in our dictionary, but 'NaN' stands for Not A Number,  and is denoted by *pd.NaT*. Do not use quotes when you include this value. NaN means Not A Number, and NaT means Not A Time - both of these values represent undefined or unrepresenable values like 0/0. They are functionally Null values. Don't worry, we'll help you with this.\n",
    "\n",
    "Call the **rename()** method on *properties_T* and set the *columns* keyword equal to the following dictionary: \n",
    "{'Unnamed: 0':'London_Borough', pd.NaT: 'ID'} \n",
    ", then reassign that value to properties_T to update the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okin_8huoQve"
   },
   "outputs": [],
   "source": [
    "# Try this here. \n",
    "properties_T = properties_T._ _ _(columns = {'Unnamed: 0':'London_Borough', pd.NaT: 'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tf5sGPzgoQvh"
   },
   "outputs": [],
   "source": [
    "# Let's check out the DataFrame again to admire our good work. \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNaq3UB2oQvk"
   },
   "source": [
    "You're making great leaps forward. But your DataFrame still has lots of columns. Find out exactly how many by calling ***.columns*** on our DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mk3GoJQ0oQvk"
   },
   "outputs": [],
   "source": [
    "# Try this here. \n",
    "properties_T.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoABG7qfoQvl"
   },
   "source": [
    "#### 2.4. Transforming the data\n",
    "Your data would be tidier if you had fewer columns. \n",
    "\n",
    "Wouldn't a ***single*** column for time be better than nearly 300? This single column will contain all of the datetimes in your current column headings. \n",
    "\n",
    "**Remember** the two most important properties of tidy data are:\n",
    "1. **Each column is a variable.**\n",
    "\n",
    "2. **Each row is an observation.**\n",
    "\n",
    "One of the miraculous things about pandas is ***melt()***, which enables you to melt those values along the column headings of your current DataFrame into a single column.  \n",
    "\n",
    "Make a new DataFrame called clean_properties, and assign it the return value of ***pd.melt()*** with the parameters: *properties_T* and *id_vars = ['Borough', 'ID']*. \n",
    "\n",
    "The result will be a DataFrame with rows representing the average house price within a given month and a given borough. Exactly what you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UVaoHRqLoQvm"
   },
   "outputs": [],
   "source": [
    "# Try this here: \n",
    "clean_properties = pd._ _ _(properties_T, id_vars= ['London_Borough', 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LTOV_GqToQvp"
   },
   "outputs": [],
   "source": [
    "clean_properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCNCHx-boQvq"
   },
   "source": [
    "Awesome. This is looking good. \n",
    "\n",
    "Rename the '0' column 'Month', and the 'value' column 'Average_price'. \n",
    "\n",
    "Use the ***rename()*** method, and reassign *clean_properties* with the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O18-PumMoQvq"
   },
   "outputs": [],
   "source": [
    "# Re-name the column names\n",
    "clean_properties = clean_properties._ _ _(columns = {0: 'Month', 'value': 'Average_price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1c_fzdqoQvs"
   },
   "outputs": [],
   "source": [
    "# Check out the DataFrame: \n",
    "clean_properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9dC_BTloQvt"
   },
   "source": [
    "You need to check out the data types of your clean_properties DataFrame, just in case you need to do any type conversions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmsH2Qb_oQvu"
   },
   "outputs": [],
   "source": [
    "# Let's use the .dtypes attribute to check the data types of our clean_properties DataFrame:\n",
    "clean_properties._ _ _ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g43As823oQvv"
   },
   "source": [
    "Change the Average_price column to a numeric type, specifically, a float.\n",
    "\n",
    "Call the ***to_numeric()*** method on *pd*, pass the 'Average_price' column into its brackets, and reassign the result to the *clean_properties* 'Average_price' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBY_XhNgoQvw"
   },
   "outputs": [],
   "source": [
    "# Try this here\n",
    "clean_properties['Average_price'] = pd._ _ _(clean_properties['Average_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QoziBdLjoQvx"
   },
   "outputs": [],
   "source": [
    "# Check out the new data types:\n",
    "clean_properties.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2nqprK3oQvz"
   },
   "outputs": [],
   "source": [
    "# To see if there are any missing values, we should call the count() method on our DataFrame:\n",
    "clean_properties._ _ _()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q0q23GdGoQv0"
   },
   "source": [
    "#### 2.5. Cleaning the data (Part 3) \n",
    "Houston, we have a problem!\n",
    "\n",
    "There are fewer data points in some of the columns. Why might this be? Let's investigate.\n",
    "\n",
    "Since there are only 32 London boroughs, check out the unique values of the 'London_Borough' column to see if they're all there.\n",
    "\n",
    "Just call the ***unique()*** method on the London_Borough column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NeMCe5LnoQv1"
   },
   "outputs": [],
   "source": [
    "# Do this here. \n",
    "clean_properties['London_Borough']._ _ _()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJrRfavtoQv2"
   },
   "source": [
    "Aha! Some of these strings are not London boroughs. You're basically Sherlock Holmes, getting ever closer solving the mystery! \n",
    "\n",
    "The strings that don't belong:\n",
    "- 'Unnamed: 34'\n",
    "- 'Unnamed: 37'\n",
    "- 'NORTH EAST'\n",
    "- 'NORTH WEST'\n",
    "- 'YORKS & THE HUMBER' \n",
    "- 'EAST MIDLANDS'\n",
    "- 'WEST MIDLANDS'\n",
    "- 'EAST OF ENGLAND'\n",
    "- 'LONDON' \n",
    "- 'SOUTH EAST' \n",
    "- 'SOUTH WEST'\n",
    "- 'Unnamed: 47' \n",
    "- 'England'\n",
    "\n",
    "See what information is contained in rows where London_Boroughs is 'Unnamed’ and, if there’s nothing valuable, you can drop them.  To investigate, subset the clean_properties DataFrame on this condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfSR55C6oQv3"
   },
   "outputs": [],
   "source": [
    "# Subset clean_properties on the condition: df['London_Borough'] == 'Unnamed: 34' to see what information these rows contain. \n",
    "clean_properties[clean_properties['_ _ _'] == '_ _ _'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExzOt8PvoQv4"
   },
   "outputs": [],
   "source": [
    "# Let's do the same for 'Unnamed: 37':\n",
    "clean_properties[clean_properties['London_Borough'] _ _ _ 'Unnamed: 37'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bbhle6-XoQv6"
   },
   "source": [
    "These rows don't contain any valuable information. Delete them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kES5fUO-oQv7"
   },
   "outputs": [],
   "source": [
    "# Let's look at how many rows have NAs as their value for ID. \n",
    "# To this end, subset clean_properties on the condition: clean_properties['ID'].isna().\n",
    "# Notice that this line doesn't actually reassign a new value to clean_properties. \n",
    "clean_properties[clean_properties['ID']._ _ _()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SwqI6XSwoQv8"
   },
   "source": [
    "You always have a ***choice*** about how to deal with Null (NaN) values. We show you two methods today:\n",
    "1. filtering on ***notna()***\n",
    "2. reassigning on ***dropna()***\n",
    "\n",
    "Try ***notna()*** first.  ***notna()*** will return a series of booleans, where the value will be true if there's a not a null and false if there is a null.\n",
    "\n",
    "Make a new variable called *NaNFreeDF1* and assign it the result of filtering *clean_properties* on the condition: *clean_properties['Average_price'].notna()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2EiVsSToQv9"
   },
   "outputs": [],
   "source": [
    "# Try your hand at method (1) here: \n",
    "NaNFreeDF1 = clean_properties[_ _ _['Average_price'].notna()]\n",
    "NaNFreeDF1.head(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUqiWHguoQv_"
   },
   "outputs": [],
   "source": [
    "# If we do a count on our new DataFrame, we'll see how many rows we have that have complete information: \n",
    "NaNFreeDF1._ _ _()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9R6TVgaoQwA"
   },
   "source": [
    "Looks good! \n",
    "\n",
    "For completeness, now use ***dropna()***. ***dropna()*** will drop all null values. \n",
    "\n",
    "Make a new variable called *NaNFreeDF2*, and assign it the result of calling ***dropna()*** on *clean_properties*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynqQvnqboQwB"
   },
   "outputs": [],
   "source": [
    "# filtering the data with NaN values\n",
    "NaNFreeDF2 = clean_properties._ _ _()\n",
    "NaNFreeDF2.head(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6iE0x_PoQwC"
   },
   "outputs": [],
   "source": [
    "# Let's do a count on this DataFrame object: \n",
    "NaNFreeDF2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SqSbEp1joQwE"
   },
   "outputs": [],
   "source": [
    "NaNFreeDF2['London_Borough'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6edHTKZBoQwG"
   },
   "source": [
    "Both these methods did the job! Thus, you can pick either resultant DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOtPflNroQwG"
   },
   "outputs": [],
   "source": [
    "# Using the .shape attribute, compare the dimenions of clean_properties, NaNFreeDF1, and NaNFreeDF2: \n",
    "print(clean_properties._ _ _)\n",
    "print(_ _ _.shape)\n",
    "print(NaNFreeDF2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TY9HeuzvoQwI"
   },
   "source": [
    "Our suggestions is to pick NaNFreeDF2.\n",
    "\n",
    "Drop the rest of the invalid 'London Borough' values.\n",
    "\n",
    "An elegant way to do this is to make a list of all those invalid values, then use the isin() method, combined with the negation operator ~, to remove those values. Call this list nonBoroughs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0TwKbiqpoQwI"
   },
   "outputs": [],
   "source": [
    "# A list of non-boroughs. \n",
    "nonBoroughs = ['Inner London', 'Outer London', \n",
    "               'NORTH EAST', 'NORTH WEST', 'YORKS & THE HUMBER', \n",
    "               'EAST MIDLANDS', 'WEST MIDLANDS',\n",
    "              'EAST OF ENGLAND', 'LONDON', 'SOUTH EAST', \n",
    "              'SOUTH WEST', 'England']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i399VSG3oQwJ"
   },
   "source": [
    "Filter *NanFreeDF2* first on the condition that the rows' values for *London_Borough* is *in* the *nonBoroughs* list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6__ch4duoQwK"
   },
   "outputs": [],
   "source": [
    "# Do this here. \n",
    "NaNFreeDF2[NaNFreeDF2.London_Borough.isin(_ _ _)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxH7n2kGoQwM"
   },
   "source": [
    "You can now just put the negation operator *~* before the filter statement to get just those rows whose values for *London_Borough* is **not** in the *nonBoroughs* list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1iNoiSuyoQwM"
   },
   "outputs": [],
   "source": [
    "NaNFreeDF2[_ _ _NaNFreeDF2.London_Borough.isin(nonBoroughs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0DqBCTRyoQwP"
   },
   "source": [
    "Then execute the reassignment: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-c8tBbr_oQwP"
   },
   "outputs": [],
   "source": [
    "NaNFreeDF2 = NaNFreeDF2[~NaNFreeDF2.London_Borough.isin(nonBoroughs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKradDB9oQwR"
   },
   "outputs": [],
   "source": [
    "NaNFreeDF2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XHpJ9wAGoQwT"
   },
   "source": [
    "Make a new variable called 'df', which is what data scientists typically name their final, analysis-ready DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuI9BMQkoQwT"
   },
   "outputs": [],
   "source": [
    "# Do that here. \n",
    "_ _ _ = NaNFreeDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZzDELq0oQwV"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8huM_mDNoQwW"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_X3wY68oQwY"
   },
   "source": [
    "#### 2.6. Visualizing the data\n",
    "Time to get a visual idea of the price shift occurring in the London boroughs. \n",
    "\n",
    "Restrict your observations to Camden for now. \n",
    "\n",
    "How have housing prices changed since 1995?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZT-6VyndoQwY"
   },
   "outputs": [],
   "source": [
    "# First of all, make a variable called camden_prices, and assign it the result of filtering df on the following condition:\n",
    "# df['London_Borough'] == 'Camden'\n",
    "camden_prices = df[df['London_Borough'] == 'Camden']\n",
    "\n",
    "# Make a variable called ax. Assign it the result of calling the plot() method, and plugging in the following values as parameters:\n",
    "# kind ='line', x = 'Month', y='Average_price'\n",
    "_ _ _ = camden_prices.plot(_ _ _ ='line', _ _ _ = 'Month', y='_ _ _')\n",
    "\n",
    "# Finally, call the set_ylabel() method on ax, and set that label to the string: 'Price'. \n",
    "ax.set_ylabel('_ _ _')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rn48QxyhoQwf"
   },
   "source": [
    "To limit the amount of temporal data-points you have, it would be useful to extract the year from every value in our *Month* column. 300 is more datapoints than you need.\n",
    "\n",
    "To this end, you'll apply a ***lambda function***. The logic works as follows. You'll:\n",
    "1. look through the `Month` column\n",
    "2. extract the year from each individual value in that column \n",
    "3. store that corresponding year as separate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "em58veREoQwg"
   },
   "outputs": [],
   "source": [
    "# Try this yourself. \n",
    "df['Year'] = df['Month'].apply(lambda t: t.year)\n",
    "\n",
    "# Call the tail() method on df\n",
    "df._ _ _()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wKBkCQWPoQwh"
   },
   "source": [
    "To calculate the mean house price for each year, you first need to **group by** the London_Borough and Year columns.\n",
    "\n",
    "Make a new variable called *dfg*, and assign it the result of calling the ***groupby()*** method on *df*. Plug in the parameters: by=['Borough', 'Year']. To get the ***mean()*** of the result you'll chain that onto the end. \n",
    "\n",
    "We've helped you with this line, it's a little tricky. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WWN5eAHvoQwh"
   },
   "outputs": [],
   "source": [
    "# Using the function 'groupby' will help you to calculate the mean for each year and for each Borough. \n",
    "## As you can see, the variables Borough and Year are now indices\n",
    "dfg = _ _ _._ _ _(by=['London_Borough', 'Year']).mean()\n",
    "dfg.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJgOyKvToQwi"
   },
   "outputs": [],
   "source": [
    "# Let's reset the index for our new DataFrame dfg, and call the head() method on it. \n",
    "dfg = dfg._ _ _()\n",
    "dfg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idY2Tm0LoQwk"
   },
   "source": [
    "### 3. Modelling\n",
    "Now comes the really exciting stuff. \n",
    "\n",
    "You want to create a function that will calculate a ratio of house prices, that compares the price of a house in 2018 to the price in 1998. \n",
    "\n",
    "Call this function create_price_ratio. \n",
    "\n",
    "You want this function to:\n",
    "\n",
    "1. Take a filter of dfg, specifically where this filter constrains the London_Borough, as an argument. For example, one admissible argument should be: **dfg[dfg['London_Borough']=='Camden']**. \n",
    "\n",
    "2. Get the Average Price for that borough for 1998 and, seperately, for 2018. \n",
    "\n",
    "3. Calculate the ratio of the Average Price for 1998 divided by the Average Price for 2018. \n",
    "\n",
    "4. Return that ratio. \n",
    "\n",
    "Once you've written this function, you'll use it to iterate through all the unique London_Boroughs and work out the ratio capturing the difference of house prices between 1998 and 2018.\n",
    "\n",
    "***Hint***: This section should test the skills you acquired in:\n",
    "- Python Data Science Toolbox (Part 1), all modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKfXa3rGoQwk"
   },
   "outputs": [],
   "source": [
    "# Here's where you should write your function:\n",
    "def create_price_ratio(d):\n",
    "    y1998 = float(d['Average_price'][d['Year']==1998])\n",
    "    y2018 = float(d['Average_price'][d['Year']==2018])\n",
    "    ratio = [y2018/_ _ _]\n",
    "    return ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnF3gQlnoQwn"
   },
   "outputs": [],
   "source": [
    "#  Test out the function by calling it with the following argument:\n",
    "# dfg[dfg['London_Borough']=='Barking & Dagenham']\n",
    "create_price_ratio(_ _ _[dfg['London_Borough']=='Barking & Dagenham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWcFNNn7oQwo"
   },
   "outputs": [],
   "source": [
    "# We want to do this for all of the London Boroughs. \n",
    "# First, let's make an empty dictionary, called final, where we'll store our ratios for each unique London_Borough.\n",
    "final = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85z1F-L6oQwq"
   },
   "outputs": [],
   "source": [
    "# Now let's declare a for loop that will iterate through each of the unique elements of the 'London_Borough' column of our DataFrame dfg.\n",
    "# Call the iterator variable 'b'. \n",
    "for b in dfg['London_Borough'].unique():\n",
    "    # Let's make our parameter to our create_price_ratio function: i.e., we subset dfg on 'London_Borough' == b. \n",
    "    borough = dfg[dfg['London_Borough'] == b]\n",
    "    # Make a new entry in the final dictionary whose value's the result of calling create_price_ratio with the argument: borough\n",
    "    final[b] = create_price_ratio(borough)\n",
    "# We use the function and incorporate that into a new key of the dictionary \n",
    "print(final) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4_LiJPsoQws"
   },
   "source": [
    "Now you have a dictionary with data about the ratio of average prices for each borough between 1998 and 2018,  but you can make it prettier by converting it to a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Kb7S98SoQws"
   },
   "outputs": [],
   "source": [
    "# Make a variable called df_ratios, and assign it the result of calling the DataFrame method on the dictionary final. \n",
    "_ _ _ = pd.DataFrame(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0kihAAPoQwu"
   },
   "outputs": [],
   "source": [
    "# Call the head() method on this variable to check it out. \n",
    "df_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "384p6TkYoQww"
   },
   "outputs": [],
   "source": [
    "# All we need to do now is transpose it, and reset the index! \n",
    "df_ratios_T = _ _ _.T\n",
    "df_ratios = df_ratios_T.reset_index()\n",
    "df_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X89wxuVkoQwy"
   },
   "outputs": [],
   "source": [
    "# Let's just rename the 'index' column as 'London_Borough', and the '0' column to '2018'.\n",
    "df_ratios.rename(columns={'index':'Borough', 0:'2018'}, inplace=True)\n",
    "df_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6zzYXIYoQwz"
   },
   "outputs": [],
   "source": [
    "# Let's sort in descending order and select the top 15 boroughs.\n",
    "# Make a variable called top15, and assign it the result of calling sort_values() on df_ratios. \n",
    "_ _ _ = df_ratios._ _ _(by='2018',ascending=False).head(15)\n",
    "print(top15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_gebsa2oQw0"
   },
   "outputs": [],
   "source": [
    "# Let's plot the boroughs that have seen the greatest changes in price.\n",
    "# Make a variable called ax. Assign it the result of filtering top15 on 'Borough' and '2018', then calling plot(), with\n",
    "# the parameter kind = 'bar'. \n",
    "ax = top15[['Borough','_ _ _']].plot(kind='bar')\n",
    "\n",
    "ax.set_xticklabels(top15.Borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WvYdrxHboQw1"
   },
   "source": [
    "### 4. Conclusion\n",
    "Congratulation!  You're done. Excellent work.\n",
    "\n",
    "What can you conclude? Type your conclusions below. \n",
    "\n",
    "We hope you enjoyed this practical project. It should have consolidated your data cleaning and pandas skills by looking at a real-world problem with the kind of dataset you might encounter as a budding data scientist. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Springboard Data Science Career Track Unit 4 Challenge - Tier 1 Complete.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
